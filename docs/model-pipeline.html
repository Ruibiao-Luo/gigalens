
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Modelling Pipeline &#8212; GIGALens  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Bibliography and Acknowledgements" href="bib.html" />
    <link rel="prev" title="Lens Simulation" href="simulation.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="modelling-pipeline">
<h1>Modelling Pipeline<a class="headerlink" href="#modelling-pipeline" title="Permalink to this headline">¶</a></h1>
<p>Our current modelling pipeline has three steps.</p>
<span class="target" id="module-gigalens.inference"></span><dl class="py class">
<dt class="sig sig-object py" id="gigalens.inference.ModellingSequenceInterface">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">gigalens.inference.</span></span><span class="sig-name descname"><span class="pre">ModellingSequenceInterface</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phys_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sim_config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gigalens/inference.html#ModellingSequenceInterface"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gigalens.inference.ModellingSequenceInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the three steps in modelling:</p>
<ol class="arabic simple">
<li><p>Multi-starts gradient descent to find the maximum a posteriori (MAP) estimate. See <span id="id1">Martí [<a class="reference internal" href="bib.html#id245" title="Rafael Martí. Multi-Start Methods. In Fred Glover and Gary A. Kochenberger, editors, Handbook of Metaheuristics, International Series in Operations Research &amp; Management Science, pages 355–368. Springer US, Boston, MA, 2003. URL: https://doi.org/10.1007/0-306-48056-5_12 (visited on 2021-11-04), doi:10.1007/0-306-48056-5_12.">Marti03</a>], György and Kocsis [<a class="reference internal" href="bib.html#id150" title="András György and Levente Kocsis. Efficient multi-start strategies for local search algorithms. Journal of Artificial Intelligence Research, 41:407–444, 2011. doi:10.1613/jair.3313.">GyorgyK11</a>]</span>.</p></li>
<li><p>VI using the MAP as a starting point. See <span id="id2">Hoffman <em>et al.</em> [<a class="reference internal" href="bib.html#id162" title="Matthew D Hoffman, David M Blei, Chong Wang, and John Paisley. Stochastic variational inference. Journal of Machine Learning Research, 2013.">HBWP13</a>], Blei <em>et al.</em> [<a class="reference internal" href="bib.html#id36" title="David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. Variational inference: a review for statisticians. Journal of the American Statistical Association, 112(518):859–877, Apr 2017. URL: http://dx.doi.org/10.1080/01621459.2017.1285773, doi:10.1080/01621459.2017.1285773.">BKM17</a>]</span>.</p></li>
<li><p>HMC using the inverse of the VI covariance matrix as the mass matrix <span class="math notranslate nohighlight">\(M\)</span>. See <span id="id3">Duane <em>et al.</em> [<a class="reference internal" href="bib.html#id96" title="Simon Duane, A.D. Kennedy, Brian J. Pendleton, and Duncan Roweth. Hybrid Monte Carlo. Physics Letters B, 195(2):216–222, September 1987. URL: https://linkinghub.elsevier.com/retrieve/pii/037026938791197X (visited on 2021-09-16), doi:10.1016/0370-2693(87)91197-X.">DKPR87</a>], Neal [<a class="reference internal" href="bib.html#id264" title="Radford Neal. MCMC Using Hamiltonian Dynamics, pages 113-162. CRC Press, 2011. doi:10.1201/b10905.">Neal11</a>]</span>.</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>phys_model</strong> (<a class="reference internal" href="model-spec.html#gigalens.model.PhysicalModel" title="gigalens.model.PhysicalModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PhysicalModel</span></code></a>) – The physical model of the lensing system that we want to fit</p></li>
<li><p><strong>prob_model</strong> (<a class="reference internal" href="model-spec.html#gigalens.model.ProbabilisticModel" title="gigalens.model.ProbabilisticModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ProbabilisticModel</span></code></a>) – The probabilistic model of the data we are fitting</p></li>
<li><p><strong>sim_config</strong> (<a class="reference internal" href="simulation.html#gigalens.simulator.SimulatorConfig" title="gigalens.simulator.SimulatorConfig"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SimulatorConfig</span></code></a>) – Parameters for image simulation (e.g., pixel scale)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="gigalens.inference.ModellingSequenceInterface.MAP">
<em class="property"><span class="pre">abstract</span> </em><span class="sig-name descname"><span class="pre">MAP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gigalens/inference.html#ModellingSequenceInterface.MAP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gigalens.inference.ModellingSequenceInterface.MAP" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds maximum a posteriori (MAP) estimates for the parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> – An optimizer object with which to run MAP. Adam or variants thereof are recommended, using a
decaying learning rate</p></li>
<li><p><strong>start</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.10)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>]) – Samples from which to start optimization. If none are provided, optimization will be started by
sampling directly from the prior</p></li>
<li><p><strong>n_samples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – Number of samples with which to run multi-starts gradient descent</p></li>
<li><p><strong>num_steps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – Number of gradient descent steps</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.10)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>]) – A random seed (only necessary if <code class="docutils literal notranslate"><span class="pre">start</span></code> is not specified)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The <em>unconstrained</em> parameters of all <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> samples after running <code class="docutils literal notranslate"><span class="pre">num_steps</span></code> of optimization.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gigalens.inference.ModellingSequenceInterface.SVI">
<em class="property"><span class="pre">abstract</span> </em><span class="sig-name descname"><span class="pre">SVI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_vi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gigalens/inference.html#ModellingSequenceInterface.SVI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gigalens.inference.ModellingSequenceInterface.SVI" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs stochastic variational inference (SVI) to characterize the posterior scales. Currently, only
multi-variate Gaussian ansatz is supported.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> – An optimizer with which to minimize the ELBO loss. Adam or variants thereof are recommended,
using slow learning rate warm-up.</p></li>
<li><p><strong>start</strong> – Initial guess for posterior mean. Must be shape <cite>(1,d)</cite>, where <cite>d</cite> is the number of parameters.
Convention is that it is in unconstrained parameter space.</p></li>
<li><p><strong>n_vi</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – Number of samples with which to approximate the ELBO loss</p></li>
<li><p><strong>num_steps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – Number of optimization steps</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.10)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>) – A random seed for drawing samples from the posterior ansatz</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The fitter posterior in <em>unconstrained</em> space</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gigalens.inference.ModellingSequenceInterface.HMC">
<em class="property"><span class="pre">abstract</span> </em><span class="sig-name descname"><span class="pre">HMC</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">q_z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_eps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_l</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_hmc</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_burnin_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_results</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_leapfrog_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gigalens/inference.html#ModellingSequenceInterface.HMC"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gigalens.inference.ModellingSequenceInterface.HMC" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs Hamiltonian Monte Carlo (HMC) to draw posterior samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>q_z</strong> – Fitted posterior from SVI. Used to calculate the mass matrix <span class="math notranslate nohighlight">\(M\)</span> for preconditioned HMC.
Convention is that <code class="docutils literal notranslate"><span class="pre">q_z</span></code> is an approximation of the <em>unconstrained</em> posterior.</p></li>
<li><p><strong>init_eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – Initial step size :math::<cite>epsilon</cite></p></li>
<li><p><strong>init_l</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – Initial number of leapfrog steps <span class="math notranslate nohighlight">\(L\)</span></p></li>
<li><p><strong>n_hmc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – Number of HMC chains to run in parallel</p></li>
<li><p><strong>num_burnin_steps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – Number of burn-in steps</p></li>
<li><p><strong>num_results</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – Number of samples to draw from each chain (after burning in)</p></li>
<li><p><strong>max_leapfrog_steps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – Maximum number of leapfrog steps if <span class="math notranslate nohighlight">\(L\)</span> is tuned automatically</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.10)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>) – A random seed</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Posterior chains in <em>unconstrained</em> space</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">GIGALens</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="philosophy.html">Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="model-spec.html">Model Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="simulation.html">Lens Simulation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Modelling Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="bib.html">Bibliography and Acknowledgements</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="simulation.html" title="previous chapter">Lens Simulation</a></li>
      <li>Next: <a href="bib.html" title="next chapter">Bibliography and Acknowledgements</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Andi Gu.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/model-pipeline.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>